{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1_FeatureAnalysisAndComputation.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/magiwanders/CMLS_HW1/blob/master/1_FeatureAnalysisAndComputation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IfSP1QdOmiHK"
      },
      "source": [
        "# **FEATURE ANALYSIS FOR THE DATASET**\n",
        "### Extract, plot and compare different features for the dataset (e.g. MFCC). Choose the features that enable the best differentiation between the classes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_iz_L7onC2L"
      },
      "source": [
        "# Mount the drive and enter the dataset directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEkgXe_RmesK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbfc9e1d-5462-4f5d-9e0b-0073ee7480b3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd \"/content/drive/MyDrive/CMLS_HW1_UrbanClassification/dataset\"\n",
        "%ls | grep fold"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/CMLS_HW1_UrbanClassification/dataset'\n",
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXSIlhPMnMML"
      },
      "source": [
        "# Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4seGkmINnYZa"
      },
      "source": [
        "import numpy as np\n",
        "import librosa\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn.svm\n",
        "import IPython.display as ipd\n",
        "import scipy as sp\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import re\n",
        "import pickle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TAQOJup3CAYz"
      },
      "source": [
        "#Import the Dataset Metadata"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzyMS3lqndOO"
      },
      "source": [
        "metadata = pd.read_csv('UrbanSound8K.csv')\n",
        "metadata.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BgoshUtonaTL"
      },
      "source": [
        "# Define helper functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UpoWZcC-0GrK"
      },
      "source": [
        "def compute_mfcc(audio, fs, win_length, hop_size, n_mfcc):\n",
        "    # Compute the spectrogram of the audio signal\n",
        "    X = np.abs(librosa.stft(\n",
        "        audio,\n",
        "        window='hamming',\n",
        "        n_fft=win_length,\n",
        "        hop_length=hop_size,)\n",
        "        )\n",
        "    \n",
        "    # Find the weights of the mel filters\n",
        "    mel = librosa.filters.mel(\n",
        "        sr=fs,\n",
        "        n_fft=win_length,\n",
        "        n_mels=40,\n",
        "        fmin=0,\n",
        "        fmax=fs,\n",
        "    )\n",
        "    \n",
        "    # Apply the filters to spectrogram\n",
        "    melspectrogram = np.dot(mel, X)\n",
        "    # Take the logarithm\n",
        "    log_melspectrogram = np.log10(melspectrogram + 1e-16)\n",
        "    \n",
        "    # Apply the DCT to log melspectrogram to obtain the coefficients\n",
        "    mfcc = sp.fftpack.dct(log_melspectrogram, axis=0, norm='ortho')[1:n_mfcc+1]\n",
        "    return mfcc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "roNZ6pc7yZPU"
      },
      "source": [
        "def extract_features(x, fs, win_length, hop_size, n_mfcc):\n",
        "    mfcc = compute_mfcc(x, fs, win_length, hop_size, n_mfcc);\n",
        "\n",
        "    # take the statistics over time of the mfccs\n",
        "    min = np.min(mfcc, axis=1);\n",
        "    max = np.max(mfcc, axis=1);\n",
        "    mean = np.mean(mfcc, axis=1);\n",
        "    median = np.median(mfcc, axis=1);\n",
        "    variance = np.var(mfcc, axis=1);\n",
        "\n",
        "    # in total I should have 25*5 = 125 features per audio frame\n",
        "    features = np.empty((0,125))\n",
        "    ext_features = np.hstack([min, max, mean, median, variance])\n",
        "    features = np.vstack([features,ext_features])\n",
        "\n",
        "    return features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iNYq08Qsn7ho"
      },
      "source": [
        "# Compute the features for each dataset fold"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2NFjkvaob5h"
      },
      "source": [
        "# Assume that the dataset is in the current directory\n",
        "dataset_path = Path(\".\")\n",
        "\n",
        "Fs = 22050;\n",
        "\n",
        "win_length = int(np.ceil(0.0232*Fs))   # should return a 512 samples window\n",
        "hop_size = int(0.5*win_length)\n",
        "\n",
        "n_mfcc = 25;\n",
        "\n",
        "mfcc_data = []\n",
        "\n",
        "# For each directory, which corresponds to a fold ...\n",
        "for current_fold_dir in dataset_path.iterdir():\n",
        "  # Check if the directory is really a directory\n",
        "  if current_fold_dir.is_dir():\n",
        "    # Save the current fold number\n",
        "    current_fold_number = re.findall('[0-9-]+', str(current_fold_dir)) # Extract the fold number with regex\n",
        "    print(\"Scanning fold {} of 10\" .format(current_fold_number))#, end='\\x1b[1K\\r') # Status printing with line clearing\n",
        "\n",
        "    # For each audio file in current_fold_dir\n",
        "    for current_audio_dir in (current_fold_dir).iterdir():\n",
        "      # Check if it's really a file and not a fold\n",
        "      if not current_audio_dir.is_dir() and os.path.splitext(current_audio_dir)[1] == '.wav' and current_fold_number[0] == '1' :\n",
        "        filename = current_audio_dir.stem + '.wav'\n",
        "        print(\"Currently processing: {}\" .format(filename))\n",
        "      \n",
        "        x, sr = librosa.load(current_audio_dir, sr=Fs)\n",
        "\n",
        "        features = extract_features(x, Fs, win_length, hop_size, n_mfcc)\n",
        "\n",
        "        metadata_row = metadata.loc[metadata['slice_file_name']==filename].values.tolist()\n",
        "        label = metadata_row[0][-1];\n",
        "        label_id = metadata_row[0][-2];\n",
        "        fold = metadata_row[0][-3]\n",
        "        \n",
        "        mfcc_data.append([features, features.shape, label_id, label, fold])\n",
        "\n",
        "#///////////////////////////////////////////////////////////////////////////////\n",
        "#///////////////////// PARALLELIZED EQUIVALENT /////////////////////////////////\n",
        "#///////////////////////////////////////////////////////////////////////////////\n",
        "\n",
        "# def analyze_folder(current_fold_dir):\n",
        "#   # Check if the directory is really a directory\n",
        "#   if current_fold_dir.is_dir():\n",
        "#     # Save the current fold number\n",
        "#     current_fold_number = re.findall('[0-9-]+', str(current_fold_dir)) # Extract the fold number with regex\n",
        "#     print(\"Scanning fold {} of 10\" .format(current_fold_number))#, end='\\x1b[1K\\r') # Status printing with line clearing\n",
        "\n",
        "#     # For each audio file in current_fold_dir\n",
        "#     for current_audio_dir in (current_fold_dir).iterdir():\n",
        "#       # Check if it's really a file and not a fold\n",
        "#       if not current_audio_dir.is_dir() and os.path.splitext(current_audio_dir)[1] == '.wav' and current_fold_number[0] == '1' :\n",
        "#         filename = current_audio_dir.stem + '.wav'\n",
        "#         print(\"Currently processing: {}\" .format(filename))\n",
        "      \n",
        "#         x, sr = librosa.load(current_audio_dir, sr=Fs)\n",
        "\n",
        "#         features = extract_features(x, Fs, win_length, hop_size, n_mfcc)\n",
        "\n",
        "#         metadata_row = metadata.loc[metadata['slice_file_name']==filename].values.tolist()\n",
        "#         label = metadata_row[0][-1];\n",
        "#         label_id = metadata_row[0][-2];\n",
        "#         fold = metadata_row[0][-3]\n",
        "        \n",
        "#         mfcc_data.append([features, features.shape, label_id, label, fold])\n",
        "\n",
        "# if __name__ == '__main__':\n",
        "#     out_parall = p_map(analyze_folder, dataset_path.iterdir())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88YXyPTFFFMb"
      },
      "source": [
        "cols=[\"features\", \"shape\",\"label_id\", \"label\", \"fold\"]\n",
        "mfcc_pd = pd.DataFrame(data = mfcc_data, columns=cols)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZGhHwM5_x3i"
      },
      "source": [
        "mfcc_pd.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEB4jjdI_8TW"
      },
      "source": [
        "labels = set(mfcc_pd['label'])\n",
        "print(labels)\n",
        "cnt = [[label,list(mfcc_pd['label']).count(label)] for label in labels]\n",
        "dict_cnt = dict(cnt)\n",
        "dict_cnt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WH6mNjXXAQrb"
      },
      "source": [
        "ll = [mfcc_pd['features'][i].ravel() for i in range(mfcc_pd.shape[0])]\n",
        "mfcc_pd['sample'] = pd.Series(ll, index=mfcc_pd.index)\n",
        "del mfcc_pd['features']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPIGTjuSAahs"
      },
      "source": [
        "mfcc_pd.head()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}